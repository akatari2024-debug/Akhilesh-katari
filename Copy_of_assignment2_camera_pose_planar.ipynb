{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akatari2024-debug/Akhilesh-katari/blob/main/Copy_of_assignment2_camera_pose_planar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLzrHXZd2Ues"
      },
      "source": [
        "# Assignment 2 â€” Camera Pose from a Planar ObjectColab-ready notebook with a Gradio UI to click points, estimate pose via Homographyâ†’Pose and OpenCV `solvePnP`, and visualize overlays.Run all cells in order. The first cell installs compatible packages for Colab."
      ],
      "id": "XLzrHXZd2Ues"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This helper function is correct as is.\n",
        "def homography_to_pose(H, K):\n",
        "    \"\"\"Decomposes a homography matrix to a rotation matrix and a translation vector.\"\"\"\n",
        "    H_norm = np.linalg.inv(K) @ H\n",
        "    h1, h2, h3 = H_norm[:, 0], H_norm[:, 1], H_norm[:, 2]\n",
        "    lam = 1.0 / np.linalg.norm(h1)\n",
        "    r1 = lam * h1\n",
        "    r2 = lam * h2\n",
        "    r3 = np.cross(r1, r2)\n",
        "    t = lam * h3\n",
        "    R = np.column_stack((r1, r2, r3))\n",
        "    U, _, Vt = np.linalg.svd(R)\n",
        "    R = U @ Vt\n",
        "    return R, t\n",
        "\n",
        "# This helper function is correct as is.\n",
        "def draw_points_on_image(image, points):\n",
        "    \"\"\"Draws numbered circles for each point on a copy of the image.\"\"\"\n",
        "    if image is None:\n",
        "        return None\n",
        "\n",
        "    overlay = image.copy()\n",
        "    for i, (x, y) in enumerate(points):\n",
        "        cv2.circle(overlay, (int(x), int(y)), 8, (0, 255, 0), -1)\n",
        "        cv2.putText(overlay, str(i), (int(x) + 10, int(y) - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "    return overlay\n",
        "\n",
        "# ðŸ”´ NEW HELPER FUNCTION TO FIX BLACK IMAGE ISSUE\n",
        "def fix_image_type(image):\n",
        "    \"\"\"\n",
        "    Robustly converts a NumPy image array to uint8 for display.\n",
        "    Handles float arrays in both 0-1 and 0-255 ranges.\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        return None\n",
        "    # If it's already uint8, do nothing\n",
        "    if image.dtype == np.uint8:\n",
        "        return image\n",
        "\n",
        "    # If it's a float, we need to scale it correctly\n",
        "    if image.dtype == np.float32 or image.dtype == np.float64:\n",
        "        # Check if the max value is around 1.0, indicating a normalized image\n",
        "        if image.max() <= 1.0:\n",
        "            image = (image * 255).astype(np.uint8)\n",
        "        else: # Otherwise, assume it's already in the 0-255 range\n",
        "            image = image.astype(np.uint8)\n",
        "        return image\n",
        "\n",
        "    # For other types, try a direct conversion\n",
        "    return image.astype(np.uint8)\n",
        "\n",
        "\n",
        "def process(image, intrinsics_json, points):\n",
        "    \"\"\"\n",
        "    Estimates camera pose from an undistorted image and corresponding 2D points.\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        return \"Please upload an image first!\", None, None\n",
        "    if len(points) < 4:\n",
        "        return f\"Need at least 4 points! Currently have {len(points)}.\", None, None\n",
        "\n",
        "    try:\n",
        "        intr = json.loads(intrinsics_json)\n",
        "        original_K = np.array(intr[\"K\"])\n",
        "        original_dist = np.array(intr[\"dist\"])\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        K, _ = cv2.getOptimalNewCameraMatrix(original_K, original_dist, (w, h), 1, (w, h))\n",
        "        dist = np.zeros(5)\n",
        "\n",
        "        img_pts = np.array(points, dtype=np.float32)\n",
        "\n",
        "        model_pts = np.array([\n",
        "            [0, 0, 0], [1, 0, 0], [1, 1, 0], [0, 1, 0]\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        success, rvec, tvec = cv2.solvePnP(model_pts, img_pts, K, dist)\n",
        "        if not success:\n",
        "            return \"solvePnP failed. Check if points are co-linear.\", None, None\n",
        "\n",
        "        R_cv, _ = cv2.Rodrigues(rvec)\n",
        "        overlay = image.copy()\n",
        "        proj_pts, _ = cv2.projectPoints(model_pts, rvec, tvec, K, dist)\n",
        "\n",
        "        for i, pt in enumerate(proj_pts):\n",
        "            x, y = int(pt[0][0]), int(pt[0][1])\n",
        "            cv2.circle(overlay, (x, y), 8, (0, 0, 255), -1)\n",
        "            cv2.putText(overlay, f\"P{i}\", (x + 10, y + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "        for i, (x, y) in enumerate(img_pts.astype(int)):\n",
        "            cv2.circle(overlay, (x, y), 8, (0, 255, 0), -1)\n",
        "            cv2.putText(overlay, f\"C{i}\", (x + 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "        axis_3d = np.float32([[0,0,0], [1,0,0], [0,1,0], [0,0,-1]]).reshape(-1, 3) * 0.75\n",
        "        axis_2d, _ = cv2.projectPoints(axis_3d, rvec, tvec, K, dist)\n",
        "        origin = tuple(axis_2d[0].ravel().astype(int))\n",
        "        cv2.line(overlay, origin, tuple(axis_2d[1].ravel().astype(int)), (0, 0, 255), 3)\n",
        "        cv2.line(overlay, origin, tuple(axis_2d[2].ravel().astype(int)), (0, 255, 0), 3)\n",
        "        cv2.line(overlay, origin, tuple(axis_2d[3].ravel().astype(int)), (255, 0, 0), 3)\n",
        "\n",
        "        fig = plt.figure(figsize=(8, 6))\n",
        "        ax = fig.add_subplot(111, projection=\"3d\")\n",
        "\n",
        "        R_cam_to_world = R_cv.T\n",
        "        t_cam_in_world = -R_cam_to_world @ tvec\n",
        "\n",
        "        ax.quiver(0, 0, 0, 1, 0, 0, color=\"k\", label=\"World X\", arrow_length_ratio=0.1)\n",
        "        ax.quiver(0, 0, 0, 0, 1, 0, color=\"k\", label=\"World Y\", arrow_length_ratio=0.1)\n",
        "        ax.quiver(0, 0, 0, 0, 0, 1, color=\"k\", label=\"World Z\", arrow_length_ratio=0.1)\n",
        "\n",
        "        cam_x, cam_y, cam_z = t_cam_in_world.flatten()\n",
        "        ax.scatter(cam_x, cam_y, cam_z, c='purple', marker='o', s=100, label='Camera Center')\n",
        "        cam_axes = R_cam_to_world * 0.5\n",
        "        ax.quiver(cam_x, cam_y, cam_z, cam_axes[0, 0], cam_axes[1, 0], cam_axes[2, 0], color=\"r\", label=\"Cam X\")\n",
        "        ax.quiver(cam_x, cam_y, cam_z, cam_axes[0, 1], cam_axes[1, 1], cam_axes[2, 1], color=\"g\", label=\"Cam Y\")\n",
        "        ax.quiver(cam_x, cam_y, cam_z, cam_axes[0, 2], cam_axes[1, 2], cam_axes[2, 2], color=\"b\", label=\"Cam Z\")\n",
        "\n",
        "        ax.set_title(\"Camera Pose in World Coordinates\")\n",
        "        ax.set_xlabel(\"X\"); ax.set_ylabel(\"Y\"); ax.set_zlabel(\"Z\")\n",
        "        ax.legend()\n",
        "        ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "        reprojection_error = np.mean(np.linalg.norm(img_pts - proj_pts.squeeze(), axis=1))\n",
        "        out_text = (f\"âœ… Pose Estimated!\\n\\n\"\n",
        "                    f\"Reprojection Error: {reprojection_error:.2f} pixels\\n\\n\"\n",
        "                    f\"Camera Position (in world coords):\\n\"\n",
        "                    f\"  t = [{t_cam_in_world[0][0]:.3f}, {t_cam_in_world[1][0]:.3f}, {t_cam_in_world[2][0]:.3f}]\\n\\n\"\n",
        "                    f\"Camera Rotation (world-to-camera):\\n{np.round(R_cv, 3)}\")\n",
        "\n",
        "        # ðŸ”´ Applying the robust fix before returning the image\n",
        "        return out_text, fix_image_type(overlay), fig\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\", None, None\n",
        "\n",
        "default_intrinsics = \"\"\"{\n",
        "  \"K\": [\n",
        "    [1000.0, 0.0, 500.0],\n",
        "    [0.0, 1000.0, 500.0],\n",
        "    [0.0, 0.0, 1.0]\n",
        "  ],\n",
        "  \"dist\": [0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "}\"\"\"\n",
        "with gr.Blocks(title=\"Pose Estimation Tool\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ðŸ“· Camera Pose Estimation Tool\")\n",
        "    gr.Markdown(\"Upload an image containing a flat, square object. Then **click on the 4 corners of the square in order** (e.g., bottom-left, bottom-right, top-right, top-left).\")\n",
        "\n",
        "    original_image_state = gr.State(None)\n",
        "    undistorted_image_state = gr.State(None)\n",
        "    point_state = gr.State([])\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            img_display = gr.Image(type=\"numpy\", label=\"Upload Image & Click 4 Corners\")\n",
        "            point_info = gr.Textbox(label=\"Selected Points\", interactive=False)\n",
        "        with gr.Column(scale=1):\n",
        "            intr = gr.Textbox(label=\"Camera Intrinsics (JSON)\", lines=12, value=default_intrinsics)\n",
        "\n",
        "    with gr.Row():\n",
        "        clear_btn = gr.Button(\"Clear Points\")\n",
        "        estimate_btn = gr.Button(\"Estimate Pose\", variant=\"primary\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            out_text = gr.Textbox(label=\"Pose Estimation Results\", lines=10)\n",
        "        with gr.Column(scale=2):\n",
        "            out_img = gr.Image(label=\"Image with Pose Overlay\")\n",
        "            out_fig = gr.Plot(label=\"3D Visualization of Camera Pose\")\n",
        "\n",
        "    def on_image_upload(image, intrinsics_str):\n",
        "        if image is None:\n",
        "            gr.Warning(\"Image upload failed. Please try again.\")\n",
        "            return None, None, [], \"Upload an image.\"\n",
        "        try:\n",
        "            intr = json.loads(intrinsics_str)\n",
        "            K = np.array(intr[\"K\"])\n",
        "            dist = np.array(intr[\"dist\"])\n",
        "            h, w = image.shape[:2]\n",
        "            new_K, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), 1, (w, h))\n",
        "            undistorted = cv2.undistort(image, K, dist, None, new_K)\n",
        "\n",
        "            # ðŸ”´ Applying the robust fix after undistorting\n",
        "            undistorted_fixed = fix_image_type(undistorted)\n",
        "\n",
        "            return image, undistorted_fixed, [], \"Click 4 points on the image.\"\n",
        "        except Exception as e:\n",
        "            gr.Warning(f\"Failed to undistort image: {e}\")\n",
        "            return image, image, [], \"Error: Could not process intrinsics.\"\n",
        "\n",
        "    def collect_points(evt: gr.SelectData, points, image):\n",
        "        if image is None:\n",
        "            gr.Warning(\"Please upload an image first!\")\n",
        "            return points, \"Upload an image first.\", None\n",
        "\n",
        "        new_points = points + [evt.index]\n",
        "\n",
        "        info_text = f\"Selected {len(new_points)} points.\\n\"\n",
        "        if len(new_points) < 4:\n",
        "            info_text += f\"Need {4 - len(new_points)} more.\"\n",
        "        else:\n",
        "            info_text += \"Ready to estimate pose!\"\n",
        "\n",
        "        overlay = draw_points_on_image(image, new_points)\n",
        "        return new_points, info_text, fix_image_type(overlay)\n",
        "\n",
        "    def clear_all_points(image):\n",
        "        return [], \"Points cleared.\", image\n",
        "\n",
        "    img_display.upload(\n",
        "        on_image_upload,\n",
        "        inputs=[img_display, intr],\n",
        "        outputs=[original_image_state, undistorted_image_state, point_state, point_info]\n",
        "    ).then(\n",
        "        lambda x: x, inputs=undistorted_image_state, outputs=img_display\n",
        "    )\n",
        "\n",
        "    img_display.select(\n",
        "        collect_points,\n",
        "        inputs=[point_state, undistorted_image_state],\n",
        "        outputs=[point_state, point_info, img_display]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        clear_all_points,\n",
        "        inputs=[undistorted_image_state],\n",
        "        outputs=[point_state, point_info, img_display]\n",
        "    )\n",
        "\n",
        "    estimate_btn.click(\n",
        "        process,\n",
        "        inputs=[undistorted_image_state, intr, point_state],\n",
        "        outputs=[out_text, out_img, out_fig]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "UlgpR7Y7GYoS",
        "outputId": "f51e560e-7e4a-4c73-cc1b-5c9dfd0a586b"
      },
      "id": "UlgpR7Y7GYoS",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cb56bc26be5e498b3f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cb56bc26be5e498b3f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}